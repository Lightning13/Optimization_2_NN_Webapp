is_package: true
container:
  type: HtmlTemplate
  properties: {html: '@theme:standard-page.html'}
components:
- type: ColumnPanel
  properties: {}
  name: content_panel
  layout_properties: {slot: default}
  components:
  - name: rich_text_1
    properties: {content: '**Our CNN model**'}
    type: RichText
    layout_properties: {grid_position: 'SFHDEN,JTXSYL'}
  - name: rich_text_2
    properties: {content: '**CNN**


        In our journey to harness the full potential of Convolutional Neural Networks
        (**CNNs**) for the **MNIST dataset**, we embarked on an exploration that delved
        deep into the intricacies of network design using both **TensorFlow** and
        **PyTorch**. Our aim was not just to adhere to the **TensorFlow** framework
        as suggested by our course guidelines but to extend our investigation into
        **PyTorch**, motivated by a curiosity to discern any impactful differences
        between the two frameworks.


        **TensorFlow Model**


        In our **TensorFlow** model designed for the **MNIST dataset**, the architecture
        was meticulously crafted to optimize performance through a blend of convolutional
        layers, batch normalization, ReLU activations, and strategic dropout implementation.
        This model represents a harmonious integration of complexity and regularization,
        tailored to capture the intricate patterns of handwritten digits with high
        accuracy.


        **Initial Architecture and Adjustments**


        Our model initiates with a first convolutional block consisting of two convolutional
        layers, each equipped with 32 filters of size 3x3. This choice was guided
        by the aim to commence feature extraction effectively, identifying basic shapes
        and edges crucial for early digit recognition. After observing initial results,
        it became apparent that while this setup was effective for basic patterns,
        enhancing the model''s depth was necessary for capturing more complex features.


        Moving to the second convolutional block, we increased the filter count to
        64 while maintaining the kernel size. This adjustment was based on our experimentation,
        which showed that a higher number of filters at this stage allowed the network
        to build a more nuanced understanding of the input images, such as the curves
        and intersections unique to different digits.


        **Key Breakthrough with Dropout**


        A significant turning point in our model''s development was our approach to
        dropout regularization. Initially, we implemented a conservative dropout rate
        of 0.3 after the max-pooling layers in our first and second convolutional
        blocks. This was based on early experiments indicating minor overfitting,
        where we observed a slight but noticeable gap between training and validation
        accuracies, approximately 98.5% to 98% respectively.


        However, the real breakthrough came when we decided to further refine the
        dropout strategy. Specifically, after the third convolutional block, where
        we had escalated the filter count to 128 to delve into even more detailed
        feature extraction, we increased the dropout rate to 0.4. This was a calculated
        decision to counteract the increased complexity and potential overfitting
        associated with deeper layers.


        The final dense layer before classification was another critical focus area.
        Recognizing the importance of this layer in interpreting the high-level features
        extracted by the convolutional blocks, we introduced a dropout rate of 0.5.
        This higher rate before the softmax classification layer marked a pivotal
        adjustment, ensuring that our model maintained robustness and generalization
        ability, effectively narrowing the gap between training and validation accuracy
        to a mere 0.2%.


        **Testing and Results Analysis**


        **PyTorch Model**


        For our **PyTorch** model designed to classify the **MNIST dataset**, we meticulously
        crafted an architecture that encapsulates our understanding of effective deep
        learning practices. The model is a testament to our iterative design process,
        where each layer and technique is purposefully selected to enhance the model''s
        ability to discern and classify complex patterns in handwritten digits.


        **Architecture and Strategic Enhancements**


        Our **PyTorch** model, **CNN**, begins its feature extraction journey with
        a convolutional layer sequence designed for progressive complexity. The initial
        layer starts with 32 filters of size 3x3, a decision made to capture the fundamental
        aspects of the images such as edges and basic shapes. This is immediately
        followed by batch normalization and ReLU activation to ensure a stable and
        non-linear processing of the input data. The inclusion of a max-pooling layer
        after each convolutional and activation sequence serves to reduce the spatial
        dimensions while preserving the most salient features.


        As we advance deeper into the network, the number of filters in the convolutional
        layers increases from 32 to 64, and finally to 128. This gradual increase
        is not arbitrary; it is based on our empirical findings that a deeper network
        with more filters at later stages is more adept at capturing the intricate
        details necessary for accurate digit classification. The consistent application
        of batch normalization across these layers plays a crucial role in maintaining
        the efficiency of the training process by normalizing the layer inputs.


        **Critical Role of Dropout in Regularization**


        A pivotal aspect of our **PyTorch** model is the strategic use of dropout,
        particularly within the fully connected layers. Recognizing the potential
        for overfitting with increased model complexity, we implemented a dropout
        rate of 0.5 both before and after the dense layer comprising 512 units. This
        aggressive regularization approach significantly contributed to the model''s
        robustness, ensuring that it generalizes well to unseen data by preventing
        it from relying too heavily on any single feature.


        **Forward Pass and Model Integration**


        The forward pass of our model is streamlined yet powerful, with the convolutional
        layers feeding into a flattened layer that transforms the 2D feature maps
        into a 1D vector. This vector is then processed through the fully connected
        layers, where the dropout regularization is applied. The culmination of this
        process is a softmax output that classifies the input image into one of the
        ten digit categories.


        **Testing and Results Analysis**


        Upon comparing the outcomes from both **TensorFlow** and **PyTorch** models,
        it was evident that while each framework offers unique advantages, the core
        principles of effective network design—such as strategic layering and judicious
        use of regularization techniques—remain constant. Our experiments did not
        yield a significant difference in the final accuracy between the two models,
        with both achieving and marginally surpassing the 99.5% accuracy mark on the
        validation set. This parity in performance underscores the notion that the
        choice between **TensorFlow** and **PyTorch** may come down to personal preference
        or specific project requirements rather than inherent superiority in handling
        image classification tasks.'}
    type: RichText
    layout_properties: {grid_position: 'DLIKWH,ZNYANY'}
- type: FlowPanel
  properties: {}
  name: navbar_links
  layout_properties: {slot: nav-right}
- name: button_1
  properties: {text: Go Back, icon: 'fa:arrow-left'}
  type: Button
  layout_properties: {slot: title}
  event_bindings: {click: button_1_click}
- name: button_2
  properties: {text: 'Dive into our models?', bold: true, icon: 'fa:arrow-circle-right',
    font_size: 29}
  type: Button
  layout_properties: {slot: default}
  event_bindings: {click: button_2_click}
